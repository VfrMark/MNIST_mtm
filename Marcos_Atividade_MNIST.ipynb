{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Marcos_Atividade_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VfrMark/MNIST_mtm/blob/main/Marcos_Atividade_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSi49U-E899I"
      },
      "source": [
        "Neste notebook será desenvolvido um classificador MNIST com 'data augmentation' das imagens de treinamento.\n",
        "\n",
        "Este projeto faz parte de uma atividade avaliativa da disciplina MTM3587-08222 (20212) - Aprendizado da Máquina lecionada pelo Prof. Edson.\n",
        "\n",
        "Aluno: Marcos Rosa - 18100695"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbuf2o-UZL-x"
      },
      "source": [
        "#MNIST\n",
        "\n",
        "Neste pequeno notebook ilustraremos a aplicação de alguns conceitos de Machine Learning relativas ao problema de classificação de dígitos. Devido ao tamanho do dataset, não é intenção do notebook fazer otimizações de modelos, mas tão somente ilustrar alguns conceitos tais como:\n",
        "\n",
        "*   Visualização de imagens à partir de matrizes em escalas de cinza\n",
        "*   SGDClassifier (sklearn)\n",
        "*   GridSearch\n",
        "*   Tópicos em classificação multiclasse\n",
        "\n",
        "Bom aprendizado!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hHU7cjTZL-_"
      },
      "source": [
        "# Configurações iniciais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TOFvglyZL_A"
      },
      "source": [
        "\n",
        "Inicialmente, vamos importar alguns módulos comuns e configurar o matplotlib para funcionar mais elegantemente, além de configurar um módulo para salvar figuras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZGRnOQ5ZL_B"
      },
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "\n",
        "# Para ajudar na reproducibilidade\n",
        "# Aqui a seed é 42, mas não há nada de especial nisso\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(fig_id, format='png', dpi=600)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKM38I6yZL_C"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMVcnYnFYcmx"
      },
      "source": [
        "Vamos agora importar o [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database), que um largo conjunto de dados que contém anotações à mão de dígitos, de 0 à 9. \n",
        "\n",
        "É um dataset muito utilizado para aprendizado, assim como referência quando se pretende testar novos algoritmos de classificação.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz4ZuB2AZCV2"
      },
      "source": [
        " Vamos precisar importar o conjunto de dados. O sklearn já vem com uma rotina para buscar alguns datasets públicos, como é caso do MNIST. Para isso vamos utilizar 'fetch_openml()' para buscar o nosso conjunto de dados.\n",
        "\n",
        "<font color= '#5A35B6'>**Atenção:**</font>  A função `fetch_mldata()` está obsoleta desde o Scikit-Learn 0.20. Devemos, ao invés disso, utilizar o `fetch_openml()`. Observa que seguindo as boas práticas de ML, a nova função já retorna o MNIST de forma não ordenada, enquanto que `fetch_mldata()` retorna o conjunto de dados ordenados pelo rótulo. Poderá então haver diferenças dependendo da versão que você utilizar. Recomenda-se que você atualize a sua versão do sklearn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUuGpUJFbxnV"
      },
      "source": [
        "#Importando dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "mnist.target = mnist.target.astype(np.int8) # fetch_openml() returns targets as strings"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6iYdbpycU0U"
      },
      "source": [
        "Vejamos o tipo dos dados que temos a nossa disposição"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDLg5otOcJ6K",
        "outputId": "05ec4fac-09c9-4e3f-dd9b-b4004f3f5947"
      },
      "source": [
        "type(mnist)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhwwkcB5cbj1"
      },
      "source": [
        "Esse tipo de dados é uma espécie de container implementada no Sklearn. Os elementos devem ser acessado através de \"chaves\" que dão acesso ao conjunto de dados. Para acessar as features, usamos a chave \"data\", ao passo que para acessar os rótulos usamos \"target\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCc7FleEb-5j",
        "outputId": "ed25c9cd-3990-46f6-9861-14093bce988f"
      },
      "source": [
        "mnist[\"data\"], mnist[\"target\"]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(       pixel1  pixel2  pixel3  pixel4  ...  pixel781  pixel782  pixel783  pixel784\n",
              " 0         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " 1         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " 2         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " 3         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " 4         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " ...       ...     ...     ...     ...  ...       ...       ...       ...       ...\n",
              " 69995     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " 69996     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " 69997     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " 69998     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " 69999     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              " \n",
              " [70000 rows x 784 columns], 0        5\n",
              " 1        0\n",
              " 2        4\n",
              " 3        1\n",
              " 4        9\n",
              "         ..\n",
              " 69995    2\n",
              " 69996    3\n",
              " 69997    4\n",
              " 69998    5\n",
              " 69999    6\n",
              " Name: class, Length: 70000, dtype: int8)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELPnpBW_dFud"
      },
      "source": [
        "Você poderia também acessar como se fosse um atributo do objeto mnist:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "_havl2iIdAkg",
        "outputId": "b6d702d8-ef5f-426c-e759-d6b4c65b8e0a"
      },
      "source": [
        "mnist.data"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-aa8722d0-6dff-40ef-9e36-ed0ea303dfc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>pixel40</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>147.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70000 rows × 784 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa8722d0-6dff-40ef-9e36-ed0ea303dfc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa8722d0-6dff-40ef-9e36-ed0ea303dfc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa8722d0-6dff-40ef-9e36-ed0ea303dfc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       pixel1  pixel2  pixel3  pixel4  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "1         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "2         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "3         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "4         0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "...       ...     ...     ...     ...  ...       ...       ...       ...       ...\n",
              "69995     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "69996     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "69997     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "69998     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "69999     0.0     0.0     0.0     0.0  ...       0.0       0.0       0.0       0.0\n",
              "\n",
              "[70000 rows x 784 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOyFcyoLdLjw"
      },
      "source": [
        "Vejamos as dimensões da matriz \"mnist.data\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cngv8cTDZL_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7264a6b-2ecc-40f1-d876-69711533137e"
      },
      "source": [
        "mnist.data.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8LX_nlydQbu"
      },
      "source": [
        "Agora vamos instanciar as features do problemas em uma matriz X e os rótulos no vetor y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1lTRg2ZL_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3305e882-8dc4-4a5a-c8e3-19b0d5c7fe18"
      },
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyetdzuwdiSY"
      },
      "source": [
        "Temos um total de 70000 instâncias e 784 features/características. Vamos agora tentar entender melhor do que se tratam essas 784 características.\n",
        "\n",
        "Primeiramente, devemos lembrar que os nossos dados são \n",
        "<font color= '#5A35B6'>**imagens**</font>. Para ser mais preciso, as 784 representam as intesidades, na escala preto e branco, de cada pixel de uma imagem quadrada com 28px em cada dimensão. \n",
        "\n",
        "Note que 28*28 = 784.\n",
        "\n",
        "Vamos agora pegar um dígito, redimensionar em 28 por 28 pixels e visualizar essa imagem.\n",
        "\n",
        "A seguir, chamamos o \"plt\" do matplotlib, colocando como argumento três paramêmtros:\n",
        "\n",
        "- A matriz que representa a imagem;\n",
        "\n",
        "- O mapeamento de cores (color map - cmap). No nosso caso, usaremos inicialmente um esquema binário preto e branco;\n",
        "\n",
        "- Método de interpolação: originalmente a nossa imagem tem dimensões 28X28 em pixels, ao passo que o matplotlib pode dispor a imagem em outras dimensões, requerendo uma técnica \"interpolação\" para preencher pixels faltando quando redimensionamos a imagem. Para essa finalidade, recomendo usar o método a seguir usando três técnicas: 'nearest', 'gaussian' e 'lanczos'. Em cada uma delas execute o código, que vai gerar uma imagem, após isso abra a imagem em outra aba e afaste (ctrl --) e aproxime (ctrl ++) a imagem para entender esse efeito da interpolação.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HGUPU6GZL_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "faef9bb3-7bb8-4f7e-a3eb-1eb998ee5547"
      },
      "source": [
        "some_digit = X.iloc[36000].to_numpy()   #Antes estava X[3600] e não estava rodando.\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "\n",
        "plt.imshow(some_digit_image, \n",
        "           cmap = mpl.cm.binary,\n",
        "           interpolation= 'lanczos')\n",
        "\n",
        "plt.axis(\"off\") #para desligar os eixos da imagem\n",
        "\n",
        "save_fig(\"some_digit_plot\")\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving figure some_digit_plot\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZPAQHWnjwx3"
      },
      "source": [
        "Vejamos o rótulo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvC9SJHFjvaZ",
        "outputId": "e7c2c916-5c3a-49bc-ca56-bdbbc87dda17"
      },
      "source": [
        "y[36000]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmCsEWTrjjsX"
      },
      "source": [
        "Vamos agora definir uma função que servirá para plotar as imagens, que basicamente organiza o código que ilustramos anteriormente, podendo ser chamado várias vezes se quisermos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKQW4no6ZL_K"
      },
      "source": [
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary,\n",
        "               interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOv5FuLwkAIH"
      },
      "source": [
        "Agora vamos separa o nosso conjunto de treino e teste. Observe que não precisaríamos embaralhar os dados pois eles já vieram embaralhados!\n",
        "\n",
        "Mas vamo embaralhar apenas que você não se esqueça desse detalhe muito importante.\n",
        "\n",
        "Aqui estaremos utilizando 60000 imagens para treino e 10000 para teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWbFBiAoZL_O"
      },
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dAVZrvfZL_O"
      },
      "source": [
        "#Embaralhemento \n",
        "shuffle_index = np.random.permutation(60000)\n",
        "X_train, y_train = X_train.iloc[shuffle_index], y_train[shuffle_index]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD74VS7XZL_m"
      },
      "source": [
        "\n",
        "# Multiclass classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ3_Xd0b31A8"
      },
      "source": [
        "Agora vamos usar o conjunto de treinamento através de um esquema de validação cruzada para eleger o modelo mais indicado para o nosso problema. \n",
        "\n",
        "Antes disso faça um estudo sobre modelos lineares que usam Gradiente Descendente Estocástico (SGD):\n",
        "\n",
        "- Faça uma leitura sobre assunto no [**guia do usuário**](https://scikit-learn.org/stable/modules/sgd.html#sgd) do sklearn. De acordo com o guia, esses modelos lineares são bem importantes para classificação de textos e processamento natural de linguagem (NLP);\n",
        "\n",
        "- Dê uma olhada no [**SGDClassifier do sklearn**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier). Leia os parágrafos inciais da documemtanção até parte que inicia a descrição dos parâmetros da classe, preste atenção principalmente nos parâmetros: \"loss\", \"penalty\" e \"alpha\".\n",
        "\n",
        "Vamos fazer uma otimização através dos seguintes parâmetros:\n",
        "\n",
        "loss : ['hinge', 'log']\n",
        "\n",
        "alpha: [1e-4,  1e-2,  1]\n",
        "\n",
        "Pode-se incluir a penalização também, mas evitaremos muitos parâmetros pois o treinamento é demorado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxMAoACmRwIo",
        "outputId": "4fb084bb-0437-4473-93ba-f0482a33dbe8"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline #Para criar um pipeline!\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipe = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
        "             ]) #O nosso modelo passará pelo std_scaler e depois pelo estimador\n",
        "\n",
        "#Usaremos 10 epochs, por isso max_iter = 10 \n",
        "#Cuidado, valores alto de max_iter fazem o algortirmo demorar\n",
        "#Outros valores para max_iter ou random_state, vão alterar o resultado\n",
        "\n",
        "param_grid = [{'estimator__loss' : ['hinge', 'log'],\n",
        "               'estimator__alpha': [1e-4, 1e-2, 1],\n",
        "               }] #grade de parâmetros para testar\n",
        "\n",
        "\"\"\"É necessário colocar o prefixo estimator__ para indicar que os parâmetros \n",
        "serão aplicados ao estimador. Você poderia tentar otimizar o pré-processamento\n",
        "dentro do pipeline também! Mas observa que muitos parâmetros tornam o processo\n",
        "bem demora.\n",
        "\"\"\"\n",
        "\n",
        "#Quanto maior o verbose no GridSearch, mais detalhes sobre o processo\n",
        "#n_jobs = -1 signifca o número de cores da máquina (-1 usa todos)\n",
        "grid_search = GridSearchCV(pipe, param_grid, cv=5, verbose=10, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                                       ('estimator',\n",
              "                                        SGDClassifier(max_iter=10,\n",
              "                                                      random_state=42))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'estimator__alpha': [0.0001, 0.01, 1],\n",
              "                          'estimator__loss': ['hinge', 'log']}],\n",
              "             verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFq2z3afc_0i"
      },
      "source": [
        "Vamos agora visualizar os resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "20dhXNEAcZhP",
        "outputId": "7db44274-dc5d-444f-bc60-5d5c09a0e95c"
      },
      "source": [
        "results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),\n",
        "                     pd.DataFrame(grid_search.cv_results_['std_test_score'], \n",
        "                                  columns=[\"Std\"]),\n",
        "                     pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], \n",
        "                                  columns=[\"Score\"])],axis=1)\n",
        "\n",
        "results.sort_values(\"Score\", ascending=False) #Ordenamento decrescente"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9a08c3d3-ee0e-477a-a58b-b15e297c5ab5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator__alpha</th>\n",
              "      <th>estimator__loss</th>\n",
              "      <th>Std</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.002276</td>\n",
              "      <td>0.911800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>log</td>\n",
              "      <td>0.002690</td>\n",
              "      <td>0.911317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.003303</td>\n",
              "      <td>0.895133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>log</td>\n",
              "      <td>0.002763</td>\n",
              "      <td>0.894883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>hinge</td>\n",
              "      <td>0.005083</td>\n",
              "      <td>0.863683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>log</td>\n",
              "      <td>0.006217</td>\n",
              "      <td>0.840233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a08c3d3-ee0e-477a-a58b-b15e297c5ab5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a08c3d3-ee0e-477a-a58b-b15e297c5ab5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a08c3d3-ee0e-477a-a58b-b15e297c5ab5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   estimator__alpha estimator__loss       Std     Score\n",
              "0            0.0001           hinge  0.002276  0.911800\n",
              "1            0.0001             log  0.002690  0.911317\n",
              "2            0.0100           hinge  0.003303  0.895133\n",
              "3            0.0100             log  0.002763  0.894883\n",
              "4            1.0000           hinge  0.005083  0.863683\n",
              "5            1.0000             log  0.006217  0.840233"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvvD-tfVaS-0"
      },
      "source": [
        "<font color= '#5A35B6'>**Observações**</font> importantes:\n",
        "\n",
        "\n",
        "\n",
        "* Fazendo uma análise preliminar, há indícios de que uma regularização l2 com alpha 0.0001 fornece as melhores respostas. Observa ainda que o modelo está indicado que está havendo subajuste (menor alpha, menos regularização), o que indica que deveríamos procurar um modelo mais complexo para a situação.\n",
        "\n",
        "*   Outro fato importante de se observar é que não estipulamos o \"score\" no gridSearch e nesse caso o score será herdado do estimador. No nosso exemplo o SGDClassifier por padrão calcula a acurácia, então o score na tabela significa acurácia. \n",
        "\n",
        "Vamos agora treinar um modelo com os melhores parametros do GridSearch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ3H65RnvUX0",
        "outputId": "d7320512-82a4-443c-d90b-6af5ba2bbd4c"
      },
      "source": [
        "model = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
        "             ])\n",
        "\n",
        "model.set_params(**grid_search.best_params_) #Introduz no pipeline os parametros\n",
        "\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                ('estimator', SGDClassifier(max_iter=10, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di-dwmsvx_Hb",
        "outputId": "c8a45bc4-7789-46bb-c405-494dc6b42276"
      },
      "source": [
        "#Treinando o modelo\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                ('estimator', SGDClassifier(max_iter=10, random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LByZLgUJiWYg"
      },
      "source": [
        "Vamos agora pegar um elemento do conjunto de teste para dar uma pequena espiada se o modelo está funcionando. \n",
        "\n",
        "<font color= '#5A35B6'>**Cuidado**</font>: Teoricamente não se deve usar o conjunto de teste até o final do processo. Então devemos utilizar ele agora. Mas se quisermos ser bem rigorosos, no final bastaria não considerar essa única instância que faríamos esse teste preliminar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rniEmReNgQCH",
        "outputId": "83030410-e79e-4f18-ac02-5c9e014877fb"
      },
      "source": [
        "#Instanciando e treinando um digito em espcifico:\n",
        "some_digit = X_test.iloc[0]\n",
        "model.predict([some_digit])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACv01oXyyhoK",
        "outputId": "2ff9cf4e-b395-481f-c417-eccad260a34d"
      },
      "source": [
        "y_test.iloc[0]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxsO-wgEykAF"
      },
      "source": [
        "O resultado foi o esperado? \n",
        "\n",
        "O SGD é treinado em um esquema OvR, de forma que cada classe tem um estimador associado. Dessa forma, cada estimador fornece um score correspondente a uma certa classe, de forma que o algoritmo rotula a nova instância com o estimador que obteve o maior score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZys7jYGZL_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1a15aa-25ce-4ef8-ee87-1cdbdc900443"
      },
      "source": [
        "some_digit_scores = model.decision_function([some_digit])\n",
        "some_digit_scores"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1151.02879743, -1556.65704299, -1625.00768203,  -723.7029964 ,\n",
              "        -1224.37804869, -1266.90999103, -2350.40223502,   282.94034641,\n",
              "        -1326.0511831 ,  -306.38372845]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPV7z783ZL_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3319a281-e688-4655-ea2d-4730bb625396"
      },
      "source": [
        "np.argmax(some_digit_scores)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm_tGokWZL_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656c2b58-0b32-49b0-e19c-a6f58c99436f"
      },
      "source": [
        "model.classes_"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yIa_JG5zT-l"
      },
      "source": [
        "Agora nós faremos uma coisa interessante: \n",
        "\n",
        "Vamos forçar o SGD a usar esquema OvO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIBJMbkwZL_p"
      },
      "source": [
        "#classe que implementa OvO na força\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "#Vamos aumentar o número de iterações.\n",
        "#Lembra que na técnica OvO há mais treinamentos mas pode ser interessante \n",
        "#quando o modelo sofre com a escala\n",
        "\n",
        "model = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 1000, random_state=42))\n",
        "             ])\n",
        "\n",
        "model.set_params(**grid_search.best_params_)\n",
        "ovo_clf = OneVsOneClassifier(model)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I07NohmM0jLW"
      },
      "source": [
        "Façamos uma validação cruzada para verificar o desempenho:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49wQQzUg0dRB"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(ovo_clf, X_train, y_train, cv=5)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgqBycS51fio",
        "outputId": "a636de7e-bc30-4eb6-9f58-ea6e241ec29d"
      },
      "source": [
        "scores"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.91583333, 0.91516667, 0.91408333, 0.91916667, 0.91333333])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J2koe521hw7",
        "outputId": "89f1ece3-48d9-47ae-966a-34dea4ad0949"
      },
      "source": [
        "np.mean(scores)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9155166666666666"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC5ISJWL1yL2"
      },
      "source": [
        "Vamos treinar no conjunto de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBmoBigu0IZm",
        "outputId": "2f4ce682-f482-4f5d-d5c6-de078943427f"
      },
      "source": [
        "ovo_clf.fit(X_train, y_train)\n",
        "ovo_clf.predict([some_digit])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but OneVsOneClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yUB8PpT00sS"
      },
      "source": [
        "Como temos 10 classes ao todo, no esquema OvO treinamos um total de  $\\displaystyle C_{10, 2} = \\frac{10!}{(10-2)! 2! } = 45$ modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrK08FtzZL_p"
      },
      "source": [
        "len(ovo_clf.estimators_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypu3G4aF3kbM"
      },
      "source": [
        "Agora vamos preparar o nosso modelo para uma avaliação final no conjunto de teste.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCEcaJ64ZL_r"
      },
      "source": [
        "from sklearn.metrics  import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDzbfuKlZL_s"
      },
      "source": [
        "y_pred = ovo_clf.predict(X_test)\n",
        "conf_mx = confusion_matrix(y_test, y_pred)\n",
        "conf_mx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FaDkhi95qFt",
        "outputId": "d740c6df-a35a-4718-aaf2-90755c22778d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9254"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG_uFcNS-Q6f"
      },
      "source": [
        "#Agora é a sua vez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwaYz6k8-U63"
      },
      "source": [
        "Agora você deve repetir o processo, mas utilizando uma etapa de pré-processamento chamando \"data augmentation\". No caso de imagens, essa técnica pode consistir de diversas metodologias, como: aumentar o número de instâncias de treinamento com rotações e translações das imagens. \n",
        "\n",
        "Nesse caso, a tua missão é treinar um novo modelo no MNIST utilizando translações no conjunto de treinamento. Fazendo isso, ensinamos o modelo a não esperar a figura centrada na imagem, podendo aumentar sua performance no teste. \n",
        "\n",
        "**Sua tarefa:**\n",
        "\n",
        "- Crie uma função  para aumentar o conjunto de **treinamento**, de forma a fazer translações nas imagens. Após isso, você deve treinar o SGDClassifier nesse conjunto de dados aumentado.\n",
        "\n",
        "- Teste o modelo no mesmo conjunto de teste que eu separei - isso é apenas um artifício didático para comparar o data augmentation, a partir do segundo teste a estimativa do erro de generalização deveria ser corrigida se quisermos obter uma estiva de performance!\n",
        "\n",
        "\n",
        "Se você estiver com dificuldades, veja a solução do exercício 2 aqui nesse [notebook](https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb) do A. Géron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QtFpoCI-p2M"
      },
      "source": [
        "#Função que 'desloca' a imagem.\n",
        "\n",
        "from scipy.ndimage.interpolation import shift\n",
        "\n",
        "def data_augmentation(data, x, y):\n",
        "    data = data.to_numpy()\n",
        "    final_data = data.reshape((28, 28))\n",
        "    shifted_data = shift(final_data, [y, x])\n",
        "    return shifted_data.reshape([-1])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esse processo demora muito pois não esta nem um pouco otimizado\n",
        "# Mas não consegui pensar em um outro modo para fazer data augmentation\n",
        "# \"do zero\". Por isso fiz com apenas 1/3 do conjunto de treino.\n",
        "''', (-3, 0), (0, 2), (0, -3)'''\n",
        "\n",
        "X_train_augmented = X_train.copy()\n",
        "y_train_augmented = y_train.copy()\n",
        "\n",
        "for x, y in ((2, 0), (-3, 0)):\n",
        "    for i in range(20000):\n",
        "\n",
        "        image = X_train.iloc[[i]]\n",
        "        aug_image = data_augmentation(image, x, y)\n",
        "        aug_image_to_append = pd.DataFrame(aug_image, columns=[image.index[0]], index=X_train.columns).transpose()\n",
        "\n",
        "        X_train_augmented = X_train_augmented.append(aug_image_to_append)\n",
        "        y_train_augmented = y_train_augmented.append(y_train.iloc[[i]])\n",
        "\n",
        "\"\"\"X_train_augmented = np.array(X_train_augmented)\n",
        "y_train_augmented = np.array(y_train_augmented)\"\"\""
      ],
      "metadata": {
        "id": "vYCP0v-SmN4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0765d524-b082-4bca-86de-dcd0c7e62aae"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train_augmented = np.array(X_train_augmented)\\ny_train_augmented = np.array(y_train_augmented)'"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ver tamanho do dataset antes e depois o processo de data augmentation\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_train_augmented.shape)"
      ],
      "metadata": {
        "id": "_3T0QZ_vvCWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84389a6-17ed-4178-d0ab-076b7e11684d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(100000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ver também os rótulos\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_train_augmented.shape)"
      ],
      "metadata": {
        "id": "1u20fnbdvQl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281a0554-68ff-44cb-efe0-39268a9d6860"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "(100000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treinando modelo SGDClassifier com conjunto pós data augmentation"
      ],
      "metadata": {
        "id": "A0tCBLo8xjzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encontrando os melhores parâmetros com GridSearch\n",
        "\n",
        "aug_pipe = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
        "             ])\n",
        "\n",
        "aug_param_grid = [{'estimator__loss' : ['hinge', 'log'],\n",
        "               'estimator__alpha': [1e-4, 1e-2, 1],\n",
        "               }]\n",
        "\n",
        "aug_grid_search = GridSearchCV(aug_pipe, aug_param_grid, cv=5, verbose=10, n_jobs=-1)\n",
        "aug_grid_search.fit(X_train_augmented, y_train_augmented)"
      ],
      "metadata": {
        "id": "71kddFq-xw5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0328a907-6a19-4dc5-fce1-bdb055b78052"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                                       ('estimator',\n",
              "                                        SGDClassifier(max_iter=10,\n",
              "                                                      random_state=42))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'estimator__alpha': [0.0001, 0.01, 1],\n",
              "                          'estimator__loss': ['hinge', 'log']}],\n",
              "             verbose=10)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instanciando modelo final com melhores parâmetros e esquema OvO.\n",
        "\n",
        "aug_model_final = Pipeline([('std_scaler', StandardScaler()),\n",
        "                 ('estimator', SGDClassifier(max_iter = 10, random_state=42))\n",
        "             ])\n",
        "\n",
        "aug_model_final.set_params(**aug_grid_search.best_params_)\n",
        "aug_ovo_clf = OneVsOneClassifier(aug_model_final)"
      ],
      "metadata": {
        "id": "kBSksjNIzaTm"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinando o modelo no conjunto de treino pós data augmentation\n",
        "\n",
        "aug_ovo_clf.fit(X_train_augmented, y_train_augmented)"
      ],
      "metadata": {
        "id": "9yGXZPri06F5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4932a7-c701-4ea5-c82f-939bf20e7029"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsOneClassifier(estimator=Pipeline(steps=[('std_scaler', StandardScaler()),\n",
              "                                             ('estimator',\n",
              "                                              SGDClassifier(max_iter=10,\n",
              "                                                            random_state=42))]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predizer os rótulos do conjunto de teste\n",
        "\n",
        "aug_y_pred = aug_ovo_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "-BbJzbqh1gDH"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Valor de acurácia dos dois modelos treinados, um no conjunto inicial \n",
        "#e outro no conjunto pós data augmentation\n",
        "\n",
        "print(f\"Acurácia do modelo pré data augmentation: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"Acurácia do modelo pós data augmentation: {accuracy_score(y_test, aug_y_pred)}\")"
      ],
      "metadata": {
        "id": "Ce4yeykt3A2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f72b390-e6b2-4f5b-fa44-18e8b81e7d07"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do modelo pré data augmentation: 0.9254\n",
            "Acurácia do modelo pós data augmentation: 0.9133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que mesmo após o processo de data augmentation esse modelo, nesse contexto específico, retornou uma acurácia levemente inferior."
      ],
      "metadata": {
        "id": "6VVXDX-I3F_I"
      }
    }
  ]
}